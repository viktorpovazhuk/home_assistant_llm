{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135773/3221944581.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_METHODS_DIR = Path('data/docs/manual')\n",
    "METHODS_DIR = Path('data/docs/methods')\n",
    "PROMPT_SEEDS_DIR = Path('data/prompts/generation/components')\n",
    "PROMPT_COMPONENTS_DIR = Path('data/prompts/generation/components')\n",
    "VAL_PROMPT_COMPONENTS_DIR = Path('data/prompts/validation/components')\n",
    "GEN_PROMPTS_DIR = Path('data/prompts/generation/output')\n",
    "VAL_PROMPTS_DIR = Path('data/prompts/validation/output')\n",
    "PERSIST_DIR = Path(\"data/persist_dir\")\n",
    "OUTPUT_DIR = Path(\"output/\")\n",
    "MODELS_PATH = Path('models/')\n",
    "DATA_DIR = Path('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96029973f090472ca4ba1a1649a4c4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GT_PATH = DATA_DIR / 'datasets/merged/test_0.csv'\n",
    "RUN_NAME = 'gemma_2b_it_hf_ft'\n",
    "NUM_EXAMPLES = 2\n",
    "NUM_NODES = 3\n",
    "MODEL_NAME = 'google/gemma-1.1-2b-it'\n",
    "PEFT_MODEL = \"models/gemma/checkpoint-500\"\n",
    "N_CTX = 4000\n",
    "settings = {\n",
    "    'llm': MODEL_NAME,\n",
    "    'num_examples': NUM_EXAMPLES,\n",
    "    'num_nodes': NUM_NODES,\n",
    "    'n_ctx': N_CTX,\n",
    "    'peft_model': PEFT_MODEL\n",
    "}\n",
    "\n",
    "# # # # # # # # # # # # \n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=nf4_config\n",
    ")\n",
    "\n",
    "llm = PeftModel.from_pretrained(llm, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m constraint \u001b[38;5;241m=\u001b[39m JsonSchemaConstraint(schema)\n\u001b[1;32m     11\u001b[0m constrainer \u001b[38;5;241m=\u001b[39m Constrainer(HuggingfaceModel(llm))\n\u001b[0;32m---> 12\u001b[0m raw_json \u001b[38;5;241m=\u001b[39m \u001b[43mconstrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGenerate a JSON of form: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m}.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m truncated_json \u001b[38;5;241m=\u001b[39m raw_json[:constraint\u001b[38;5;241m.\u001b[39mvalidate(raw_json)\u001b[38;5;241m.\u001b[39mend_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/local_llm_function_calling/constrainer.py:221\u001b[0m, in \u001b[0;36mConstrainer.generate\u001b[0;34m(self, prefix, constraint, max_len, max_new_tokens)\u001b[0m\n\u001b[1;32m    219\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstart_generation(prefix)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens) \u001b[38;5;28;01mif\u001b[39;00m max_new_tokens \u001b[38;5;28;01melse\u001b[39;00m count():\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mget_generated()\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/local_llm_function_calling/constrainer.py:191\u001b[0m, in \u001b[0;36mConstrainer.advance_generation\u001b[0;34m(self, generation, constraint, max_len)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madvance_generation\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     generation: Generation,\n\u001b[1;32m    176\u001b[0m     constraint: Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m]],\n\u001b[1;32m    177\u001b[0m     max_len: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Advance the generation by one token\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m        bool: Whether the generation is complete\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m     done, length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_next_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/local_llm_function_calling/constrainer.py:164\u001b[0m, in \u001b[0;36mConstrainer.gen_next_token\u001b[0;34m(self, generation, constraint)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sorted_tokens:\n\u001b[0;32m--> 164\u001b[0m     generated \u001b[38;5;241m=\u001b[39m \u001b[43mgeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_generated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     fit \u001b[38;5;241m=\u001b[39m constraint(generated)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fit[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/local_llm_function_calling/model/huggingface.py:101\u001b[0m, in \u001b[0;36mHuggingfaceGeneration.get_generated\u001b[0;34m(self, candidate)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_generated\u001b[39m(\u001b[38;5;28mself\u001b[39m, candidate: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the generated sequence\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m        str: The generated sequence\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerated\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3809\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;124;03mConverts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\u001b[39;00m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;124;03mtokens and clean up tokenization spaces.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;124;03m    `str`: The decoded sentence.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[0;32m-> 3809\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mto_py_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[1;32m   3812\u001b[0m     token_ids\u001b[38;5;241m=\u001b[39mtoken_ids,\n\u001b[1;32m   3813\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3814\u001b[0m     clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3816\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/transformers/utils/generic.py:272\u001b[0m, in \u001b[0;36mto_py_obj\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: to_py_obj(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [to_py_obj(o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/transformers/utils/generic.py:272\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: to_py_obj(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mto_py_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m obj]\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# This gives us a smart order to test the frameworks with the corresponding tests.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/transformers/utils/generic.py:277\u001b[0m, in \u001b[0;36mto_py_obj\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m framework_to_test_func \u001b[38;5;241m=\u001b[39m _get_frameworks_and_test_func(obj)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m framework, test_func \u001b[38;5;129;01min\u001b[39;00m framework_to_test_func\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtest_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m framework_to_py_obj[framework](obj)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# tolist also works on 0d np arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/transformers/utils/generic.py:167\u001b[0m, in \u001b[0;36mis_torch_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_torch_tensor\u001b[39m(x):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Tests if `x` is a torch tensor or not. Safe to call even if torch is not installed.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_is_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/assistant/lib/python3.10/site-packages/transformers/utils/generic.py:160\u001b[0m, in \u001b[0;36m_is_torch\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_torch\u001b[39m(x):\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from local_llm_function_calling import Constrainer, JsonSchemaConstraint, Generator\n",
    "from local_llm_function_calling.model.huggingface import HuggingfaceModel\n",
    "\n",
    "\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"enforceOrder\": [\"name\", \"age\"]\n",
    "}\n",
    "\n",
    "constraint = JsonSchemaConstraint(schema)\n",
    "constrainer = Constrainer(HuggingfaceModel(llm))\n",
    "raw_json = constrainer.generate(\"Generate a JSON of form: {'0': '0'}.\\n\", constraint, max_len=100)\n",
    "truncated_json = raw_json[:constraint.validate(raw_json).end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"name\": \"John Doe\",\\n    \"age\": 30\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Settings,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.embeddings.utils import resolve_embed_model\n",
    "from llama_index.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  3 14:28:07 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 26%   34C    P8    13W / 215W |     15MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1288      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1411      G   /usr/bin/gnome-shell                3MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = SimpleDirectoryReader(\"data/docs\").load_data()\n",
    "\n",
    "# embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, show_progress=True, service_context=service_context\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.storage_context.persist(persist_dir=\"data/persist_dir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory consumption when loading from storage: 672MiB \\\n",
    "memory consumption when loading in-memory: 5080MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"mistral\", request_timeout=180.0)\n",
    "Settings.embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# llm = Ollama(model=\"mistral\", request_timeout=180.0)\n",
    "\n",
    "# service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"data/persist_dir\")\n",
    "\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context, show_progress=True) # , service_context=service_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 1 nodes:\n",
      "> [Node 1923e2fe-6356-4826-96cc-2b9946ca1ac3] [Similarity score:             0.730295] Method name: Temperature.GetConfig\n",
      "Method description: Properties:\n",
      "{\"id\": {\"type\": \"number\", \"des...\n",
      "> Top 1 nodes:\n",
      "> [Node 1923e2fe-6356-4826-96cc-2b9946ca1ac3] [Similarity score:             0.730295] Method name: Temperature.GetConfig\n",
      "Method description: Properties:\n",
      "{\"id\": {\"type\": \"number\", \"des...\n"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\"Get temperature in the room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method name: Temperature.GetConfig\n",
      "Method description: Properties:\n",
      "{\"id\": {\"type\": \"number\", \"description\": \"Id of the Temperature component instance\"}}\n",
      "Find the Temperature.GetConfig response properties in config section\n"
     ]
    }
   ],
   "source": [
    "for n in nodes:\n",
    "    print(n.get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_curly_braces(input_string: str) -> str:\n",
    "    # Replace '{' with '{{' and '}' with '}}' to escape curly braces\n",
    "    escaped_string = input_string.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    return escaped_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompts = [\"\"\"Devices: Cover id=1\n",
    "Functions: {context_str}\n",
    "Command: {query_str}\n",
    "JSON:\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_prompt_long = \"\"\"Sentence: Set the kitchen temperature to 25 degrees, adjust the humidity in the living room to 50%,\n",
    "# turn on the lights in the bedroom, and turn off the fan in the bathroom.\n",
    "# JSON: \"\"\"\n",
    "\n",
    "# user_prompt_very_long = \"\"\"Sentence: Turn on the lights in the kitchen, set the living room temperature to 22 degrees,\n",
    "# close the curtains in the bedroom, set the bathroom fan to auto mode, turn off the desk lamp in the office,\n",
    "# close the garage door, water the garden manually, dim the lights on the bookshelves in the library,\n",
    "# turn on the air conditioning in the gym, and put the computer in the study to sleep.\n",
    "# JSON: \"\"\"\n",
    "\n",
    "json_scheme_general = {\n",
    "    \"method\": {\n",
    "        \"type\": \"string\"\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"type\": \"object\"\n",
    "    }\n",
    "}\n",
    "\n",
    "example_1_json = {\n",
    "  \"method\":\"Cover.Open\",\n",
    "  \"params\":\n",
    "  {\n",
    "    \"id\":2\n",
    "  }\n",
    "}\n",
    "\n",
    "example_2_json = {\n",
    "  \"method\":\"Cover.GetStatus\",\n",
    "  \"params\":\n",
    "  {\n",
    "    \"id\":0\n",
    "  }\n",
    "}\n",
    "\n",
    "variables = {\n",
    "    \"instruction\": \"\"\"You are 'Al', a helpful AI Assistant that controls the devices in a house. Create a JSON object representing given command. Strictly output in JSON format.\"\"\",\n",
    "    \"json_scheme\": \"The output JSON should follow the next scheme: \" + json.dumps(json_scheme_general),\n",
    "    \"devices\": \"\"\"Cover id=1\"\"\",\n",
    "    \"user_prompt\": user_prompts[0],\n",
    "    \"example_1\": \"\"\"Devices: Cover id=2\n",
    "Functions: Name: Cover.Open\n",
    "Description: Preconditions: Cover will not accept the command if: An overvoltage error is set at the time of the request. An undervoltage error is set at the time of the request. An overtemp error is set at the time of the request. An engaged safety_switch prohibits movement in the requested direction. Cover calibration is running at the time of the request. Properties: [{'name': 'id', 'type': 'number', 'description': 'The numeric ID of the Cover component instance'}, {'name': 'duration', 'type': 'number', 'description': 'If duration is not provided, Cover will fully open, unless it times out because of maxtime_open first. If duration (seconds) is provided, Cover will move in the open direction for the specified time. duration must be in the range [0.1..maxtime_open]Optional'}] Response: null on success; error if the request can not be executed or failed \n",
    "Command: Open the cover.\n",
    "JSON: \"\"\" + json.dumps(example_1_json),\n",
    "    \"example_2\": \"\"\"Devices: Cover id=0\n",
    "Functions: Name: Cover.GetStatus\n",
    "Description: Properties: [{'name': 'id', 'type': 'number', 'description': 'The numeric ID of the Cover component instance'}] Find more about the status properties in status section \n",
    "Command: Get cover status.\n",
    "JSON: \"\"\" + json.dumps(example_2_json),\n",
    "#     \"example_3\": \"\"\"\n",
    "# Sentence: Please set the humidity level in the bedroom to 60 percents, turn on the fan in the bathroom.\n",
    "# JSON: {\n",
    "#   \"locations\": [\n",
    "#     {\n",
    "#       \"name\": \"bedroom\",\n",
    "#       \"humidity\": 60\n",
    "#     },\n",
    "#     {\n",
    "#       \"name\": \"bathroom\",\n",
    "#       \"fan\": true\n",
    "#     }\n",
    "#   ]\n",
    "# }\n",
    "# \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are 'Al', a helpful AI Assistant that controls the devices in a house. Create a JSON object representing given command. Strictly output in JSON format.\n",
      "The output JSON should follow the next scheme: {{\"method\": {{\"type\": \"string\"}}, \"params\": {{\"type\": \"object\"}}}}\n",
      "\n",
      "Devices: Cover id=2\n",
      "Functions: Name: Cover.Open\n",
      "Description: Preconditions: Cover will not accept the command if: An overvoltage error is set at the time of the request. An undervoltage error is set at the time of the request. An overtemp error is set at the time of the request. An engaged safety_switch prohibits movement in the requested direction. Cover calibration is running at the time of the request. Properties: [{{'name': 'id', 'type': 'number', 'description': 'The numeric ID of the Cover component instance'}}, {{'name': 'duration', 'type': 'number', 'description': 'If duration is not provided, Cover will fully open, unless it times out because of maxtime_open first. If duration (seconds) is provided, Cover will move in the open direction for the specified time. duration must be in the range [0.1..maxtime_open]Optional'}}] Response: null on success; error if the request can not be executed or failed \n",
      "Command: Open the cover.\n",
      "JSON: {{\"method\": \"Cover.Open\", \"params\": {{\"id\": 2}}}}\n",
      "\n",
      "Devices: Cover id=0\n",
      "Functions: Name: Cover.GetStatus\n",
      "Description: Properties: [{{'name': 'id', 'type': 'number', 'description': 'The numeric ID of the Cover component instance'}}] Find more about the status properties in status section \n",
      "Command: Get cover status.\n",
      "JSON: {{\"method\": \"Cover.GetStatus\", \"params\": {{\"id\": 0}}}}\n",
      "\n",
      "\n",
      "Devices: Cover id=1\n",
      "Functions: {context_str}\n",
      "Command: {query_str}\n",
      "JSON:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "{instruction}\n",
    "{json_scheme}\n",
    "\n",
    "{example_1}\n",
    "\n",
    "{example_2}\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = escape_curly_braces(prompt_template.format(**variables)) + '\\n\\n' + variables['user_prompt']\n",
    "\n",
    "# final_prompt = variables['user_prompt'] + '{cont}'\n",
    "\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "qa_prompt = PromptTemplate(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(text_qa_template=qa_prompt) # service_context=service_context\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    # node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    StorageContext,\n",
    ")\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are 'Al', a helpful AI Assistant that controls the devices in a house. Create a JSON object representing given command. Strictly output in JSON format.\n",
      "The output JSON should follow the next scheme: {{\"method\": {{\"type\": \"string\"}}, \"params\": {{\"type\": \"object\"}}}}\n",
      "\n",
      "Devices: Cover id=2\n",
      "Functions: Name: Cover.Open\n",
      "Description: Preconditions: Cover will not accept the command if: An overvoltage error is set at the time of the request. An undervoltage error is set at the time of the request. An overtemp error is set at the time of the request. An engaged safety_switch prohibits movement in the requested direction. Cover calibration is running at the time of the request. Properties: [{{'name': 'id', 'type': 'number', 'description': 'The numeric ID of the Cover component instance'}}, {{'name': 'duration', 'type': 'number', 'description': 'If duration is not provided, Cover will fully open, unless it times out because of maxtime_open first. If duration (seconds) is provided, Cover will move in the open direction for the specified time. duration must be in the range [0.1..maxtime_open]Optional'}}] Response: null on success; error if the request can not be executed or failed \n",
      "Command: Open the cover.\n",
      "JSON: {{\"method\": \"Cover.Open\", \"params\": {{\"id\": 2}}}}\n",
      "\n",
      "Devices: Cover id=0\n",
      "Functions: Name: Cover.GetStatus\n",
      "Description: Properties: [{{'name': 'id', 'type': 'number', 'description': 'The numeric ID of the Cover component instance'}}] Find more about the status properties in status section \n",
      "Command: Get cover status.\n",
      "JSON: {{\"method\": \"Cover.GetStatus\", \"params\": {{\"id\": 0}}}}\n",
      "\n",
      "\n",
      "Devices: Cover id=1\n",
      "Functions: {context_str}\n",
      "Command: {query_str}\n",
      "JSON:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"Close the cover.\",\n",
    "           \"I wanna cover to be closed.\",\n",
    "           \"Close cover during 20 seconds.\",\n",
    "           \"Calibrate cover, please.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 1 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.716042] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> Top 1 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.716042] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f002c15bbe0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f002c15bbe0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Sun, 03 Mar 2024 12:33:08 GMT'), (b'Content-Length', b'325')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Sun, 03 Mar 2024 12:33:08 GMT'), (b'Content-Length', b'325')])\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='8e07999e-d056-4a79-be39-8c3e284783a2', embedding=None, metadata={'file_path': 'data/docs/Cover.Close.md', 'file_name': 'Cover.Close.md', 'file_type': 'text/markdown', 'file_size': 894, 'creation_date': '2024-02-22', 'last_modified_date': '2024-02-22', 'last_accessed_date': '2024-02-22'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a36a5ee9-bbed-4cac-bc3b-b00c20ccc068', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data/docs/Cover.Close.md', 'file_name': 'Cover.Close.md', 'file_type': 'text/markdown', 'file_size': 894, 'creation_date': '2024-02-22', 'last_modified_date': '2024-02-22', 'last_accessed_date': '2024-02-22'}, hash='9b826e739db6c478480d0f511db18496134b1065a409a6dfa6ed6ce61ec810e1'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9985586a-2974-474c-9ed1-a9ff314ff1b0', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'data/docs/Cover.Calibrate.md', 'file_name': 'Cover.Calibrate.md', 'file_type': 'text/markdown', 'file_size': 1912, 'creation_date': '2024-02-22', 'last_modified_date': '2024-02-22', 'last_accessed_date': '2024-02-22'}, hash='1efacfc5704da7bdfe31056b7e082edda0ad53e0f86e0d65824d6ac6b3360ef3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='6657c503-fc35-45c9-9efb-065bd453ef2d', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1f177a4ba756a8d0c2081c508a83c890eb07244bf2c05d36cff0c9802555c89e')}, text='Method name: Cover.Close\\nMethod description: Preconditions:\\nCover will not accept the command if:\\nAn  overvoltage  error is set at the time of the request.\\nAn  undervoltage  error is set at the time of the request.\\nAn  overtemp  error is set at the time of the request.\\nAn engaged  safety_switch  prohibits movement in the requested direction.\\nCover  calibration is running at the time of the request\\nProperties:\\n{\"id\": {\"type\": \"number\", \"description\": \"The numeric ID of the Cover component instance\"}, \"duration\": {\"type\": \"number\", \"description\": \"If duration is not provided, Cover will fully close, unless it times out because of maxtime_close first. If duration (seconds) is provided, Cover will move in the close direction for the specified time. duration must be in the range [0.1..maxtime_open]Optional\"}}\\nResponse:\\nnull on success; error if the request can not be executed or failed', start_char_idx=0, end_char_idx=893, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7160422664954936)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].metadata['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.716042] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> [Node 6657c503-fc35-45c9-9efb-065bd453ef2d] [Similarity score:             0.667318] Cover config object description: The configuration of the Cover component contains information ab...\n",
      "> [Node 49a07e8b-dd3f-4583-969a-a8262b4b2992] [Similarity score:             0.666196] Method name: Cover.Open\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:\n",
      "...\n",
      "> [Node f86c93bd-5e43-4d15-9ae8-5a202a851691] [Similarity score:             0.650387] Cover status object description: The status of the Cover component contains information about the...\n",
      "> Top 4 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.716042] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> [Node 6657c503-fc35-45c9-9efb-065bd453ef2d] [Similarity score:             0.667318] Cover config object description: The configuration of the Cover component contains information ab...\n",
      "> [Node 49a07e8b-dd3f-4583-969a-a8262b4b2992] [Similarity score:             0.666196] Method name: Cover.Open\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:\n",
      "...\n",
      "> [Node f86c93bd-5e43-4d15-9ae8-5a202a851691] [Similarity score:             0.650387] Cover status object description: The status of the Cover component contains information about the...\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbc63e0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbc63e0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:57:58 GMT'), (b'Content-Length', b'533')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:57:58 GMT'), (b'Content-Length', b'533')])\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      " {\"method\": \"Cover.Close\", \"params\": {\"id\": 2}}\n",
      "\n",
      "This JSON object represents a command to close the cover with ID 2. The method name is \"Cover.Close\" and the parameters object contains only the ID of the cover component instance (2) in this case.\n",
      "---------------------\n",
      "\n",
      "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.724215] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> [Node 49a07e8b-dd3f-4583-969a-a8262b4b2992] [Similarity score:             0.682236] Method name: Cover.Open\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:\n",
      "...\n",
      "> [Node d7685496-a0b9-4fe0-811a-4011fc31912a] [Similarity score:             0.667297] Method name: Cover.SetConfig\n",
      "Method description: Preconditions:\n",
      "Cover configuration can not be ch...\n",
      "> [Node 6657c503-fc35-45c9-9efb-065bd453ef2d] [Similarity score:             0.666884] Cover config object description: The configuration of the Cover component contains information ab...\n",
      "> Top 4 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.724215] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> [Node 49a07e8b-dd3f-4583-969a-a8262b4b2992] [Similarity score:             0.682236] Method name: Cover.Open\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:\n",
      "...\n",
      "> [Node d7685496-a0b9-4fe0-811a-4011fc31912a] [Similarity score:             0.667297] Method name: Cover.SetConfig\n",
      "Method description: Preconditions:\n",
      "Cover configuration can not be ch...\n",
      "> [Node 6657c503-fc35-45c9-9efb-065bd453ef2d] [Similarity score:             0.666884] Cover config object description: The configuration of the Cover component contains information ab...\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbc6500>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbc6500>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:58:00 GMT'), (b'Content-Length', b'479')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:58:00 GMT'), (b'Content-Length', b'479')])\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      " { \"_type\": \"command\",\n",
      " \"method\": { \"type\": \"string\", \"value\": \"Cover.Close\" },\n",
      " \"params\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"number\", \"value\": 2 } } }\n",
      "}\n",
      "---------------------\n",
      "\n",
      "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.726863] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> [Node 49a07e8b-dd3f-4583-969a-a8262b4b2992] [Similarity score:             0.685622] Method name: Cover.Open\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:\n",
      "...\n",
      "> [Node d2f27147-39ea-4d4a-8259-90eb0ecafb6a] [Similarity score:             0.684939] This property is editable at any time, but note that during the cover calibration procedure (Cove...\n",
      "> [Node d7685496-a0b9-4fe0-811a-4011fc31912a] [Similarity score:             0.679667] Method name: Cover.SetConfig\n",
      "Method description: Preconditions:\n",
      "Cover configuration can not be ch...\n",
      "> Top 4 nodes:\n",
      "> [Node 8e07999e-d056-4a79-be39-8c3e284783a2] [Similarity score:             0.726863] Method name: Cover.Close\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:...\n",
      "> [Node 49a07e8b-dd3f-4583-969a-a8262b4b2992] [Similarity score:             0.685622] Method name: Cover.Open\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command if:\n",
      "...\n",
      "> [Node d2f27147-39ea-4d4a-8259-90eb0ecafb6a] [Similarity score:             0.684939] This property is editable at any time, but note that during the cover calibration procedure (Cove...\n",
      "> [Node d7685496-a0b9-4fe0-811a-4011fc31912a] [Similarity score:             0.679667] Method name: Cover.SetConfig\n",
      "Method description: Preconditions:\n",
      "Cover configuration can not be ch...\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbc7eb0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbc7eb0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:58:02 GMT'), (b'Content-Length', b'347')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:58:02 GMT'), (b'Content-Length', b'347')])\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      " {\"method\": \"Cover.Close\", \"params\": {\"id\": 2, \"duration\": 20}}\n",
      "---------------------\n",
      "\n",
      "DEBUG:llama_index.core.indices.utils:> Top 4 nodes:\n",
      "> [Node 9985586a-2974-474c-9ed1-a9ff314ff1b0] [Similarity score:             0.803782] Method name: Cover.Calibrate\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command...\n",
      "> [Node f86c93bd-5e43-4d15-9ae8-5a202a851691] [Similarity score:             0.766748] Cover status object description: The status of the Cover component contains information about the...\n",
      "> [Node 73428872-6668-4b6c-b64d-b73e5202bb17] [Similarity score:             0.754839] Method name: Cover.GoToPosition\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the comm...\n",
      "> [Node d7685496-a0b9-4fe0-811a-4011fc31912a] [Similarity score:             0.74582] Method name: Cover.SetConfig\n",
      "Method description: Preconditions:\n",
      "Cover configuration can not be ch...\n",
      "> Top 4 nodes:\n",
      "> [Node 9985586a-2974-474c-9ed1-a9ff314ff1b0] [Similarity score:             0.803782] Method name: Cover.Calibrate\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the command...\n",
      "> [Node f86c93bd-5e43-4d15-9ae8-5a202a851691] [Similarity score:             0.766748] Cover status object description: The status of the Cover component contains information about the...\n",
      "> [Node 73428872-6668-4b6c-b64d-b73e5202bb17] [Similarity score:             0.754839] Method name: Cover.GoToPosition\n",
      "Method description: Preconditions:\n",
      "Cover will not accept the comm...\n",
      "> [Node d7685496-a0b9-4fe0-811a-4011fc31912a] [Similarity score:             0.74582] Method name: Cover.SetConfig\n",
      "Method description: Preconditions:\n",
      "Cover configuration can not be ch...\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/home/vpo/miniconda3/envs/assistant/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=180.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbb3850>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f187dbb3850>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:58:05 GMT'), (b'Content-Length', b'333')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Thu, 22 Feb 2024 08:58:05 GMT'), (b'Content-Length', b'333')])\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "close.complete\n",
      " {\"method\": \"Cover.Calibrate\", \"params\": {\"id\": 1}}\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in queries:\n",
    "    response = query_engine.query(q)\n",
    "    print(response)\n",
    "    print('---------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
